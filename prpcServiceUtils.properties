# Properties file for use with PRPC Service Utilities. Update this file 
# before running the prpcServiceUtils.bat/sh script.
# Set the REST URL and the specific tool settings.
# For more information, see the Pega Platform help.

################### COMMON PROPERTIES - REST CONNECTION (REQUIRED) ################
###################################################################################
# 	pega.rest.server.url=<REST service URL> 
#	pega.rest.username=<username to access REST service>
#	pega.rest.password=<service password>

pega.rest.server.url=http://10.225.71.143:8080/prweb/PRRestService
pega.rest.username=administrator@pega.com
pega.rest.password=install
pega.rest.proxy.host=
pega.rest.proxy.port=
pega.rest.proxy.username=
pega.rest.proxy.password=
pega.rest.proxy.domain=
pega.rest.proxy.workstation=

# RESPONSE TYPE
# Accepted values are xml and json.
pega.rest.response.type=json

# USER TEMP DIRECTORY
# Will use default if not set to a valid directory.
user.temp.dir=

# CUSTOM JVM ARGS
# Any additional jvm arguments other than Max Heap Size
custom.jvm.args=

############################### SETTINGS FOR EXPORT TOOL ##########################
###################################################################################

# ARCHIVE NAME (Required unless exporting a branch)
export.archiveName=

# PRODUCT NAME AND VERSION TO EXPORT
export.productName=
export.productVersion=

# APPLICATION NAME AND VERSION TO EXPORT
export.applicationVersion=
export.applicationName=

# BRANCH NAME TO EXPORT
# Exports branch to file: BranchName_CurrentTimestamp.jar  
export.branchName=

# APPLCATION CONTEXT OF THE BRANCH RULESET TO EXPORT
# For example: PegaRULES:8
export.branchAppContext=

# EXPORT ASYNCHRONOUSLY?
# Set export.async=true to execute the export asynchronously. The system queues the job and returns a JobID to use to get the job status.
export.async=true

# EXPORT TO REPOSITORY?
export.exportToRepository=false
# Name of repository to export
export.repositoryName=
# Repository folder to export
export.repositoryFolder=

############################### SETTINGS FOR EXPOSE TOOL ##########################
###################################################################################
# CLASSES TO INCLUDE (REQUIRED)
#   classes.included: Comma-delimited list of classes to include (no spaces)
#   included.descendent: true to include descendants
expose.includedClasses=Dummy-
expose.includeDescendents=true

# CLASSES TO EXCLUDE
#   classes.excluded: Comma-delimited list of classes to exclude (no spaces)
#   excluded.descendent: If including classes with descendants (for example, Rule-),
#   you can use this to filter specific classes
expose.excludedClasses=
expose.excludeDescendents=true

# KEYS AND DATE RANGES
# Use the following arguments to specify a range of pzInsKey or pxCreateDateTime properties.
# If you provide both, only the pzInsKey range will be used.
# Format for date properties is yyyyMMddTHHmmss.SSS
# NOTE: If you provide the pzInsKey range then you may only provide ONE class with no descendants.
# Use the classes.included and provide one class).
#   startKey    Only instances with a pzInsKey equal to or greater than <start key>
#   endKey      Only instances with a pzInsKey equal to or less than <end key>
#   startDate   Only instances with a pxCreateDateTime equal to or greater than <start date>
#   endDate     Only instances with a pxCreateDateTime equal to or less than <end date>
# NOTE: When dealing with large tables, give the pzInsKey range diligently to return appropriate number of results
#       so that the pre fetch query doesn't lead to allocation errors.
# NOTE: The startKey and endKey range is considered through lexicographical ordering and not numeric ordering. 
expose.startKey=
expose.endKey=
expose.startDate=
expose.endDate=

# REINDEXING:
# Use the following argument to regenerate indexes 
expose.reindex=true

# LIMIT RULESET SCOPE
# Use the following argument to limit scope of rulesets processed.
#   full -- process pega and customer rulesets
#   pega -- process only pega rulesets
#   nonpega -- process only customer rulesets
# For performance reasons, avoid processing pega rulesets unless instructed
expose.reindexType=nonpega

# COMMIT RATE
# Specify how often to commit to the database
expose.commitRate=100

# NUMBER OF THREADS
# Defaults to number of classes being updated if no value is specified
# Set to a higher value in case of updating large sets of data
# You must have more database connections available then threads specified. If not the system locks or fails depending on
# how the connection pool max wait for connection parameter is set.
expose.numOfThreads=1

# EXPOSE ASYNCHRONOUSLY?
# Set expose.async=true to execute the expose operation asynchronously. The system queues the job and returns a JobID to use to get the job status.
expose.async=false

############################### SETTINGS FOR IMPORT TOOL ##########################
###################################################################################
# RELATIVE PATH TO ARCHIVE FROM UTILS FOLDER OR FULL PATH TO ARCHIVE
# Required only for imports from a local file system.
# If the path is a folder, all zip and jar files under the directory will be considered for import.
import.archive.path=

# IMPORT PREFERENCE PATH
# Path to a valid .json preference file.
import.preferencespath=

# IMPORT PEGA ARCHIVE OPTIONS

# Modes
# install  - Do not update existing instances, only import new instances.
#            If an instance already exists, it will not be imported. An exception
#            message will appear in the log for each instance that already exists.
# import   - Update existing instances and remove duplicates.  Handling of existing
#            instances can be overridden using the import.existing.instances property.
# hotfix   - Update existing instances and remove duplicates if newer timestamp,
#            skip updating the instance (or inserting the duplicate) if the
#            archive's instance timestamp is older.
import.mode=import

# IMPORT EXISTING INSTANCES?
# Applicable to rule and work instances
# override - For rules - If a rule with the same key exists in the system but the rule resolution properties differ (e.g. RuleSet, Version, etc), then replace the existing rule with the imported rule.
#            For work - If a work object with the same key exists but it belongs to a different application (e.g. different class hierarchy but same classgroup name and same ID prefix), replace the existing work object with the imported work object.
# skip     - For rules - If a rule with the same key exists in the system and the rule resolution properties differ, do not replace the existing rule.
#            For work  - If a work object with the same key exists but it belongs to a different application, do not replace the existing work object.
# unset - the import will fail if keys already exist either for rule instances that have different rule resolution properties, or for work objects that belong to a different applications that use the same classgroup name.
import.existingInstances=skip

# DO NOT FAIL ON ERROR?
# Set to false to fail if there is an error during import.
import.nofailonerror=false

# COMMIT RATE
# Specify how often to commit to the database.
import.commitRate=100

# COMPILE LIBRARIES AFTER IMPORT?
import.compileLibraries=true

# ALLOW IMPORT WITH MISSING DEPENDENCIES?
# Allow import even if there are missing product dependencies. Recommended value is false.
import.allowImportWithMissingDependencies=false

# PRESERVE IMPORT ORDER?
# Import archives in the user-specified order. Defaults to false, which uses timestamps to determine order.
import.preserveOrder=false

# CODESET NAME AND VERSION
# Specify which codeset name and version to load Java .class files to.
import.codesetName=Customer
import.codesetVersion=06-01-01

# IMPORT ASYNCHRONOUSLY?
# Set import.async=true to execute the import asynchronously. The system queues the job and returns a JobID to use to get the job status.
import.async=true

# BYPASS BACKUP?
# Bypasses history saving and restore point creation during import. Recommended value is false.
import.skipBackup=false

# IMPORT FROM REPOSITORY?
import.importFromRepository=false
# Name of the repository from which you want to import the archive. Case sensitive.
import.repositoryName=

# ARCHIVE TYPE
# Type of the artifact which you want to import. artifactType is case sensitive. Supported types are application, product, branch, component, rulesetversion. 
import.artifactType=

# PATH TO ARCHIVE IN REPOSITORY
# For imports from a repository, provide the path including the extension. Case sensitive.
# Ex: MyApp_01.01.01/ExportWizard/myFile.zip
import.archivePath=

# BYPASS SCHEMA IMPORT?
# Bypass generating and applying all schema changes (DDL). Recommended value is false.
import.bypassSchema=

# INSECURE OPERATORS?
# Allows importing operators in an insecure fashion. By default, new operators are disabled when imported,
# and existing operators are not updated. Setting this flag to true will not disable operators
# on import and allow updates of existing operators.
import.insecureOperators=

# IMPORT INHERITED DB NAME INSTANCES?
# Allow importing inherited instances of Data-Admin-DB-Name. By default, import will fail if there are any inherited
# Database Name instances. After confirming these instances are desired, set this property to true to enable import.
import.allowInheritedConnections=false

# BYPASS AUTOMATIC COLUMN POPULATION?
# Specify whether to bypass automatic column population after import. Recommended value is false.
import.bypassColumnPopulation=false

# BYPASS SCHEMA CHANGES FOR CORE TABLE DESCENDANTS?
# Bypass propagation of schema changes for descendants of core tables modified during import. Default value is false.
# Automatically bypassed if import.bypass.schema=true.
import.bypassSchemaChangesToDescendantTables=false

# BYPASS CLASS MIGRATION?
# Bypass migration of class instances when the class-to-table mapping changes. Default value is false.
import.bypassInstanceMigration=false

############################### SETTINGS FOR HOTFIX MANAGER #######################
###################################################################################
# HOTFIX OPERATION
# Valid values are commit, rollback, generateDDL, install, and scan.
# Rollback removes all uncommitted hotfixes from the system.
hotfix.operation=

# PATH TO DL FILE
# If generateDDL or install is chosen, provide a path to a DL-*.zip file.
hotfix.dlFilePath=

# PATH TO CATALOG FILE
# If scan is chosen, provide a path to a Catalog.zip file.
# Catalog.zip files can be obtained from DL files or downloaded from ftp://catalog:catalog!@pegaftp2.pega.com/hfix/CATALOG/61/CATALOG.ZIP
hotfix.catalogPath=

# BYPASS SCHEMA CHANGES?
# Set to true to bypass applying schema changes when installing a DL
hotfix.bypassSchema=false

# IMPORT IF ADDITIONAL CONFIGURATION NEEDED?
# Import a DL even if it requires additional configuration
hotfix.force=false

# IMPORT HOTFIX ASYNCHRONOUSLY?
# Set hotix.async=true to execute the hotfix operation asynchronously. The system queues the job and returns a JobID to use to get the job status.
hotfix.async=true

############################### GET STATUS ########################################
###################################################################################
# JOB ID
# All import, export, expose, hotfix operations, and updateAccessGroup and all asynchronous rollback operations return a JobID. Use that JobID to get the status of the operation.
getstatus.jobID=

# OPERATION NAME
# Valid operation values are import, export, expose, hotfix, rollback, and updateAccessGroup.
getstatus.operationName=

############################### MANAGE RESTORE POINTS #############################
###################################################################################
# NOTE: Restore Point operations only support JSON results

# ACTION
# list: List all available restore points.
# get: Display detailed information about a single restore point. 
# create: Create a new restore point.
# delete: Delete an existing restore point.
manageRestorePoints.action=

# RESTORE POINT NAME
# The restore point name to use for getting or deleting a restore point.
manageRestorePoints.restorePointName=

# RESTORE POINT LABEL
# The restore point label to use when creating a new restore point.
manageRestorePoints.restorePointLabel=

############################### ROLLBACK ##########################################
###################################################################################
# NOTE: Rollback only supports JSON results
# Rolling back to a restore point restores the state of all applicable rule and data instances.
# See ACTION section below for which rule and data instances are applicable to roll back.
# To roll back hotfixes, use the HOTFIX MANAGER settings.

# RESTORE POINT NAME
# Name of the restore point to roll back to
rollback.restorePointName=

# ACTION
# SystemRollback - Roll back every rule and data instance with a history record.
# UserRollback - Roll back rule and data instances modified by a specific user.
# ApplicationRollback - Roll back rule and data instances from a specific application.
rollback.action=SystemRollback

# USER NAME
# The Operator ID to use when performing UserRollback.
rollback.userName=

# APPLICATION NAME
# The Application Name and Version to use when performing ApplicationRollback.
rollback.applicationName=
rollback.applicationVersion=

# ROLLBACK ASYNCHRONOUSLY?
# Set rollback.async=true to execute the rollback asynchronously. The system queues the job and returns a JobID to use to get the job status. 
rollback.async=true

# DOWNLOAD LOG TO FILESYSTEM?
# Flag for whether or not to download the log to the filesystem when returning the result of the rollback
rollback.downloadLogToFile=true

############################### UPDATE ACCESS GROUP ###############################
###################################################################################
# APPLICATION NAME AND VERSION
# List the application name and new version number.
updateAccessGroup.applicationName=
updateAccessGroup.applicationVersion=

# ACCESS GROUPS (OPTIONAL)
# List the access groups to update. If no access groups are listed, all access groups mapped to the application are updated with the new application version. 
updateAccessGroup.groupList=

############################### SETTINGS FOR CHANGING DYNAMIC SYSTEM SETTINGS #####
###################################################################################
# PATH TO JSON FILE (REQUIRED)
# Comma-delimited list of absolute path(s) to the json files. The list must end with a semicolon.
# If the path is a folder, then all the json files in that directory will be considered recursively.
# For example: C://file1.json,C://dir1//file2.json,C://dir2;
# Sample json format
#{  
#   "dass":[  
#      {  
#         "pySetting":"true",
#         "pyPurpose":"indexing/fileMonitoring",
#         "pyOwner":"Pega-RULES"
#      },
#      {  
#         "pySetting":"Hourly",
#         "pyPurpose":"indexing/frequency",
#         "pyOwner":"Pega-RULES"
#      }
#   ]
#}
updateDASS.filePath=
